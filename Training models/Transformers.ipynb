{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0432227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c810d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f89a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.load_dataset(\"imdb\", split=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11dd3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_name = \"bert-base-uncased\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(transformer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3d519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:16<00:00, 1531.34 examples/s]\n",
      "Map: 100%|██████████| 25000/25000 [00:15<00:00, 1583.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_numericalize_example(example, tokenizer):\n",
    "    ids = tokenizer(example[\"text\"], truncation=True, padding='max_length', max_length=256)[\"input_ids\"]\n",
    "    return {\"ids\": ids}\n",
    "\n",
    "train_data = train_data.map(\n",
    "    tokenize_and_numericalize_example, fn_kwargs={\"tokenizer\": tokenizer}\n",
    ")\n",
    "test_data = test_data.map(\n",
    "    tokenize_and_numericalize_example, fn_kwargs={\"tokenizer\": tokenizer}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90acbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_index = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f299a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.25\n",
    "train_valid_data = train_data.train_test_split(test_size=test_size)\n",
    "train_data = train_valid_data[\"train\"]\n",
    "valid_data = train_valid_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e67836",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_format(type=\"torch\", columns=[\"ids\", \"label\"])\n",
    "valid_data.set_format(type=\"torch\", columns=[\"ids\", \"label\"])\n",
    "test_data.set_format(type=\"torch\", columns=[\"ids\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff7bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_ids = [torch.tensor(i[\"ids\"]) for i in batch]\n",
    "        batch_ids = nn.utils.rnn.pad_sequence(\n",
    "            batch_ids, padding_value=pad_index, batch_first=True\n",
    "        )\n",
    "        batch_label = torch.tensor([i[\"label\"] for i in batch])\n",
    "        batch = {\"ids\": batch_ids, \"label\": batch_label}\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ada7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa64748",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6a1d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, transformer, output_dim, freeze):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer\n",
    "        hidden_dim = transformer.config.hidden_size\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        if freeze:\n",
    "            for param in self.transformer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, ids):\n",
    "        output = self.transformer(ids, output_attentions=True)\n",
    "        hidden = output.last_hidden_state\n",
    "        cls_hidden = hidden[:, 0, :]\n",
    "        prediction = self.fc(torch.tanh(cls_hidden))\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feaccdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformers.AutoModel.from_pretrained(transformer_name)\n",
    "output_dim = len(train_data[\"label\"].unique())\n",
    "freeze = False\n",
    "model = Transformer(transformer, output_dim, freeze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4748f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 109,483,778 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1049acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e36f1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "691c701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    for batch in tqdm(data_loader, desc=\"training...\"):\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        label = batch[\"label\"].to(device)\n",
    "        prediction = model(ids)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "188a4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"evaluating...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "            prediction = model(ids)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8075758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51660215",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "best_valid_loss = float(\"inf\")\n",
    "metrics = collections.defaultdict(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "473bcb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   0%|          | 0/2344 [00:00<?, ?it/s]/var/folders/fp/q0m5t1y91ds296s1c7f_6w1c0000gn/T/ipykernel_14599/2839162243.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_ids = [torch.tensor(i[\"ids\"]) for i in batch]\n",
      "training...:   0%|          | 0/2344 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     train_loss, train_acc = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     valid_loss, valid_acc = evaluate(valid_data_loader, model, criterion, device)\n\u001b[32m      6\u001b[39m     metrics[\u001b[33m\"\u001b[39m\u001b[33mtrain_losses\u001b[39m\u001b[33m\"\u001b[39m].append(train_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(data_loader, model, criterion, optimizer, device)\u001b[39m\n\u001b[32m      6\u001b[39m ids = batch[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m      7\u001b[39m label = batch[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m prediction = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m loss = criterion(prediction, label)\n\u001b[32m     10\u001b[39m accuracy = get_accuracy(prediction, label)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, ids)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     hidden = output.last_hidden_state\n\u001b[32m     14\u001b[39m     cls_hidden = hidden[:, \u001b[32m0\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1144\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1137\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m   1139\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m   1142\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1144\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1156\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1157\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    684\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    685\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    686\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m         output_attentions,\n\u001b[32m    693\u001b[39m     )\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    624\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    625\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:253\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:640\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m    639\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     layer_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552\u001b[39m, in \u001b[36mBertOutput.forward\u001b[39m\u001b[34m(self, hidden_states, input_tensor)\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dropout(hidden_states)\n\u001b[32m    554\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.LayerNorm(hidden_states + input_tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train(\n",
    "        train_data_loader, model, criterion, optimizer, device\n",
    "    )\n",
    "    valid_loss, valid_acc = evaluate(valid_data_loader, model, criterion, device)\n",
    "    metrics[\"train_losses\"].append(train_loss)\n",
    "    metrics[\"train_accs\"].append(train_acc)\n",
    "    metrics[\"valid_losses\"].append(valid_loss)\n",
    "    metrics[\"valid_accs\"].append(valid_acc)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"transformer.pt\")\n",
    "    print(f\"Epoch: {epoch+1}/{n_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.3f}\")\n",
    "    print(f\"Valid Loss: {valid_loss:.3f}, Valid Acc: {valid_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6190606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(metrics[\"train_losses\"], label=\"Train Loss\")\n",
    "plt.plot(metrics[\"valid_losses\"], label=\"Valid Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(range(n_epochs))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "119cfa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(metrics[\"train_accs\"], label=\"Train Accuracy\")\n",
    "plt.plot(metrics[\"valid_accs\"], label=\"Valid Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(range(n_epochs))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79e7414c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'transformer.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtransformer.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      2\u001b[39m test_loss, test_acc = evaluate(test_data_loader, model, criterion, device)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MINI PROJECT/pytorch-sentiment-analysis-main/venv/lib/python3.12/site-packages/torch/serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'transformer.pt'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"transformer.pt\"))\n",
    "test_loss, test_acc = evaluate(test_data_loader, model, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f5ec188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device):\n",
    "    ids = tokenizer(text, truncation=True, padding='max_length', max_length=256)[\"input_ids\"]\n",
    "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
    "    prediction = model(tensor).squeeze(dim=0)\n",
    "    probability = torch.softmax(prediction, dim=-1)\n",
    "    predicted_class = prediction.argmax(dim=-1).item()\n",
    "    predicted_probability = probability[predicted_class].item()\n",
    "    return predicted_class, predicted_probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2eea2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"This film is terrible!\",\n",
    "    \"This film is great!\",\n",
    "    \"This film is not terrible, it's great!\",\n",
    "    \"This film is not great, it's terrible!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0722a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This film is terrible!\n",
      "(0, 0.5899120569229126)\n",
      "Text: This film is great!\n",
      "(0, 0.5631393194198608)\n",
      "Text: This film is not terrible, it's great!\n",
      "(0, 0.5472971200942993)\n",
      "Text: This film is not great, it's terrible!\n",
      "(0, 0.6167016625404358)\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(f\"Text: {text}\")\n",
    "    print(predict_sentiment(text, model, tokenizer, device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
